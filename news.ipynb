{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SetFit/20_newsgroups\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[\"train\"]\n",
    "test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_path = 'Alibaba-NLP/gte-base-en-v1.5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(data, max_length=4096):\n",
    "    texts, labels = data['text'], data['label']\n",
    "    embeddings_res = []\n",
    "    labels_res = []\n",
    "    for i, (text, label) in tqdm(enumerate(zip(texts, labels))):\n",
    "        input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        input_len = len(input['input_ids'][0])\n",
    "        if input_len > max_length:\n",
    "            continue \n",
    "        train_outputs = model(**input)\n",
    "        embedding = train_outputs.last_hidden_state[:, 0].detach().to('cpu').numpy()\n",
    "        embeddings_res.append(embedding)\n",
    "        labels_res.append(label)\n",
    "\n",
    "        del input, train_outputs\n",
    "        torch.cuda.empty_cache() \n",
    "    embeddings_res = np.concatenate(embeddings_res, axis=0)\n",
    "    return embeddings_res, np.array(labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11314it [06:19, 29.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings, train_labels = get_embeddings(train, max_length=4096)\n",
    "test_embeddings, test_labels = get_embeddings(test, max_length=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_embeddings.npy', train_embeddings)\n",
    "np.save('train_labels.npy', train_labels)\n",
    "np.save('test_embeddings.npy', test_embeddings)\n",
    "np.save('test_labels.npy', test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
